"""
æœºå™¨å­¦ä¹ ç»Ÿè®¡åˆ†ææ¨¡å—ï¼ˆä¿®å¤ç‰ˆï¼‰
Machine Learning Statistical Analysis Module (Fixed Version)

ä¸»è¦åŠŸèƒ½:
1. æè¿°æ€§ç»Ÿè®¡åˆ†æï¼ˆä¿ç•™ï¼‰
2. æ€§åˆ«å·®å¼‚åˆ†æï¼ˆä½¿ç”¨MLåˆ†ç±»å™¨ï¼‰
3. å¹´é¾„ç»„æ¨¡å¼è¯†åˆ«ï¼ˆä½¿ç”¨èšç±»å’Œå†³ç­–æ ‘ï¼‰
4. ç›¸å…³æ€§åˆ†æï¼ˆä½¿ç”¨æ­£åˆ™åŒ–å›å½’ï¼‰
5. æ­»äº¡æ•°é¢„æµ‹ï¼ˆä½¿ç”¨å¤šç§MLå›å½’ç®—æ³•ï¼‰
6. åå·®-æ–¹å·®å‡è¡¡åˆ†æï¼ˆå›å½’ä»»åŠ¡ï¼‰
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.linear_model import Lasso, Ridge, ElasticNet
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.svm import SVC, SVR
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.cluster import KMeans
import warnings

warnings.filterwarnings("ignore")


class MLStatistics:
    """
    æœºå™¨å­¦ä¹ ç»Ÿè®¡åˆ†æç±»
    ä½¿ç”¨MLæŠ€æœ¯æ‰§è¡Œç»Ÿè®¡åˆ†æå’Œé¢„æµ‹
    """

    def __init__(self, data):
        """
        åˆå§‹åŒ–MLç»Ÿè®¡åˆ†æå™¨

        Parameters:
        -----------
        data : pd.DataFrame
            å¤„ç†åçš„WHOæ­»äº¡ç‡æ•°æ®
        """
        self.data = data.copy()
        self.results = {}
        self.scaler = StandardScaler()
        self.label_encoders = {}

        # é¢„å¤„ç†æ•°æ®
        self._preprocess_data()

    def _preprocess_data(self):
        """æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹"""
        # å¹´é¾„ç»„æ•°å€¼ç¼–ç 
        age_encoding = {
            "0-28 days": 0.04,
            "1-59 months": 2.5,
            "5-14": 9.5,
            "15-29": 22,
            "30-49": 39.5,
            "50-59": 54.5,
            "60-69": 64.5,
            "70+": 75,
        }
        self.data["age_numeric"] = self.data["age_group"].map(age_encoding)

        # æ€§åˆ«æ¯”ä¾‹ç‰¹å¾
        self.data["male_ratio"] = self.data["male"] / (self.data["both_sexes"] + 1e-10)
        self.data["female_ratio"] = self.data["female"] / (self.data["both_sexes"] + 1e-10)

        # å¯¹æ•°å˜æ¢å¤„ç†åæ€åˆ†å¸ƒ
        self.data["log_deaths"] = np.log1p(self.data["both_sexes"])
        self.data["log_male"] = np.log1p(self.data["male"])
        self.data["log_female"] = np.log1p(self.data["female"])

        # ç¼–ç åˆ†ç±»å˜é‡
        self.label_encoders['cause_name'] = LabelEncoder()
        self.data['cause_encoded'] = self.label_encoders['cause_name'].fit_transform(self.data['cause_name'])

        self.label_encoders['age_group'] = LabelEncoder()
        self.data['age_encoded'] = self.label_encoders['age_group'].fit_transform(self.data['age_group'])

    def descriptive_statistics(self):
        """
        ä¿ç•™æè¿°æ€§ç»Ÿè®¡åˆ†æï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰
        """
        print("\n" + "=" * 50)
        print("DESCRIPTIVE STATISTICS")
        print("=" * 50)

        desc_stats = {
            "total_deaths": {
                "mean": self.data["both_sexes"].mean(),
                "median": self.data["both_sexes"].median(),
                "std": self.data["both_sexes"].std(),
                "min": self.data["both_sexes"].min(),
                "max": self.data["both_sexes"].max(),
                "q25": self.data["both_sexes"].quantile(0.25),
                "q75": self.data["both_sexes"].quantile(0.75),
            },
            "male_deaths": {
                "mean": self.data["male"].mean(),
                "median": self.data["male"].median(),
                "std": self.data["male"].std(),
                "total": self.data["male"].sum(),
            },
            "female_deaths": {
                "mean": self.data["female"].mean(),
                "median": self.data["female"].median(),
                "std": self.data["female"].std(),
                "total": self.data["female"].sum(),
            },
        }

        print("\nğŸ“Š Overall Death Statistics:")
        print(f"   Mean deaths per category: {desc_stats['total_deaths']['mean']:,.1f}")
        print(f"   Median deaths: {desc_stats['total_deaths']['median']:,.1f}")
        print(f"   Std deviation: {desc_stats['total_deaths']['std']:,.1f}")
        print(f"   Range: {desc_stats['total_deaths']['min']:,.0f} - {desc_stats['total_deaths']['max']:,.0f}")

        self.results["descriptive"] = desc_stats
        return desc_stats

    def gender_classification_analysis(self):
        """
        ä½¿ç”¨æœºå™¨å­¦ä¹ åˆ†ç±»å™¨åˆ†ææ€§åˆ«å·®å¼‚æ¨¡å¼ï¼Œå¹¶æä¾›è¯¦ç»†çš„æ€§åˆ«å¯¹æ¯”åˆ†æ
        """
        print("\n" + "=" * 50)
        print("GENDER DIFFERENCE ML ANALYSIS")
        print("=" * 50)

        # 1. é¦–å…ˆè¿›è¡Œä¼ ç»Ÿçš„æ€§åˆ«å·®å¼‚ç»Ÿè®¡åˆ†æ
        print("\nğŸ“Š Traditional Gender Difference Analysis:")

        # æ•´ä½“æ€§åˆ«å·®å¼‚
        total_male = self.data['male'].sum()
        total_female = self.data['female'].sum()
        total_both = self.data['both_sexes'].sum()

        print(f"   Total Deaths - Male: {total_male:,.0f}, Female: {total_female:,.0f}")
        print(f"   Male Ratio: {total_male/total_both:.3f}, Female Ratio: {total_female/total_both:.3f}")
        print(f"   Male/Female Ratio: {total_male/total_female:.3f}")

        # æŒ‰å¹´é¾„ç»„çš„æ€§åˆ«å·®å¼‚
        print("\nğŸ“ˆ Gender Differences by Age Group:")
        age_gender_stats = self.data.groupby('age_group').agg({
            'male': 'sum',
            'female': 'sum',
            'both_sexes': 'sum'
        }).reset_index()

        # å®‰å…¨è®¡ç®—æ¯”ä¾‹ï¼Œé¿å…é™¤é›¶
        age_gender_stats['male_ratio'] = age_gender_stats['male'] / (age_gender_stats['both_sexes'] + 1e-10)
        age_gender_stats['female_ratio'] = age_gender_stats['female'] / (age_gender_stats['both_sexes'] + 1e-10)
        age_gender_stats['m_f_ratio'] = age_gender_stats['male'] / (age_gender_stats['female'] + 1e-10)

        for _, row in age_gender_stats.iterrows():
            print(f"   {row['age_group']:15} M:{row['male_ratio']:.3f} F:{row['female_ratio']:.3f} M/F:{row['m_f_ratio']:.2f}")

        # æŒ‰æ­»å› çš„æ€§åˆ«å·®å¼‚ï¼ˆTop 10ï¼‰
        print("\nğŸ”¬ Top 10 Causes with Largest Gender Differences:")
        cause_gender_stats = self.data.groupby('cause_name').agg({
            'male': 'sum',
            'female': 'sum',
            'both_sexes': 'sum'
        }).reset_index()

        # å®‰å…¨è®¡ç®—æ¯”ä¾‹ï¼Œé¿å…é™¤é›¶
        cause_gender_stats['male_ratio'] = cause_gender_stats['male'] / (cause_gender_stats['both_sexes'] + 1e-10)
        cause_gender_stats['female_ratio'] = cause_gender_stats['female'] / (cause_gender_stats['both_sexes'] + 1e-10)
        cause_gender_stats['m_f_ratio'] = cause_gender_stats['male'] / (cause_gender_stats['female'] + 1e-10)
        cause_gender_stats['abs_diff'] = abs(cause_gender_stats['male'] - cause_gender_stats['female'])

        top_causes = cause_gender_stats.nlargest(10, 'abs_diff')
        for _, row in top_causes.iterrows():
            if row['female'] == 0:
                gender_trend = "Male-only"
                ratio_text = "âˆ"
            elif row['male'] == 0:
                gender_trend = "Female-only"
                ratio_text = "âˆ"
            else:
                gender_trend = "Male-dominant" if row['male'] > row['female'] else "Female-dominant"
                ratio_text = f"{row['m_f_ratio']:.2f}"

            print(f"   {row['cause_name'][:40]:40} M/F:{ratio_text} ({gender_trend})")

        # 2. æœºå™¨å­¦ä¹ åˆ†ç±»åˆ†æ
        print("\n" + "=" * 50)
        print("MACHINE LEARNING CLASSIFICATION ANALYSIS")
        print("=" * 50)

        # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
        features = ['age_numeric', 'both_sexes', 'log_deaths', 'cause_encoded']
        X = self.data[features]
        y = (self.data['male'] > self.data['female']).astype(int)  # 1=ç”·æ€§æ­»äº¡æ›´å¤š

        # æ ‡å‡†åŒ–ç‰¹å¾
        X_scaled = self.scaler.fit_transform(X)

        # å¤šç§åˆ†ç±»å™¨æ¯”è¾ƒ
        classifiers = {
            'KNN': KNeighborsClassifier(),
            'SVM': SVC(probability=True),
            'Decision Tree': DecisionTreeClassifier(max_depth=5),
            'Random Forest': RandomForestClassifier(n_estimators=100),
            'LDA': LinearDiscriminantAnalysis()
        }

        results = {}

        for name, clf in classifiers.items():
            # äº¤å‰éªŒè¯è¯„ä¼°
            cv_scores = cross_val_score(clf, X_scaled, y, cv=5, scoring='accuracy')

            # è®­ç»ƒæ¨¡å‹
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.3, random_state=42, stratify=y
            )
            clf.fit(X_train, y_train)

            # æµ‹è¯•é›†è¯„ä¼°
            test_score = clf.score(X_test, y_test)

            # é¢„æµ‹æ¦‚ç‡ï¼ˆå¯¹äºæ”¯æŒæ¦‚ç‡çš„æ¨¡å‹ï¼‰
            if hasattr(clf, 'predict_proba'):
                y_proba = clf.predict_proba(X_test)
                confidence = np.mean(np.max(y_proba, axis=1))
            else:
                confidence = "N/A"

            results[name] = {
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'test_accuracy': test_score,
                'confidence': confidence,
                'model': clf
            }

            print(f"ğŸ“ˆ {name}:")
            print(f"   CV Accuracy: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")
            print(f"   Test Accuracy: {test_score:.3f}")
            if confidence != "N/A":
                print(f"   Avg Confidence: {confidence:.3f}")

        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model = max(results.items(), key=lambda x: x[1]['test_accuracy'])
        print(f"\nğŸ† Best Model: {best_model[0]} (Accuracy: {best_model[1]['test_accuracy']:.3f})")

        # 3. ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œæ·±å…¥åˆ†æ
        print("\n" + "=" * 50)
        print("INSIGHTS FROM BEST MODEL")
        print("=" * 50)

        best_clf = best_model[1]['model']

        # ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆå¯¹äºæ ‘æ¨¡å‹ï¼‰
        if best_model[0] in ['Decision Tree', 'Random Forest']:
            importances = best_clf.feature_importances_
            feature_importance = pd.DataFrame({
                'feature': features,
                'importance': importances
            }).sort_values('importance', ascending=False)

            print("\nğŸ“Š Feature Importance for Gender Prediction:")
            for _, row in feature_importance.iterrows():
                print(f"   {row['feature']}: {row['importance']:.3f}")

        # é¢„æµ‹åˆ†æï¼šæ‰¾å‡ºæ¨¡å‹æœ€å®¹æ˜“é¢„æµ‹å’Œæœ€éš¾é¢„æµ‹çš„æ¡ˆä¾‹
        X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        best_clf.fit(X_train_full, y_train_full)
        y_pred = best_clf.predict(X_test_full)

        # åˆ†æé¢„æµ‹æ­£ç¡®çš„æ¡ˆä¾‹
        correct_predictions = X_test_full[y_pred == y_test_full]
        incorrect_predictions = X_test_full[y_pred != y_test_full]

        print(f"\nğŸ“ˆ Model Performance Insights:")
        print(f"   Correctly predicted: {len(correct_predictions)}/{len(y_test_full)} ({len(correct_predictions)/len(y_test_full):.3f})")
        print(f"   Incorrectly predicted: {len(incorrect_predictions)}/{len(y_test_full)} ({len(incorrect_predictions)/len(y_test_full):.3f})")

        # åˆ†ææœ€å®¹æ˜“æ··æ·†çš„æƒ…å†µ
        if len(incorrect_predictions) > 0:
            print("\nğŸ¤” Most Confusing Cases (Incorrect Predictions):")
            # è·å–åŸå§‹æ•°æ®ä¸­å¯¹åº”çš„è®°å½•
            incorrect_indices = incorrect_predictions.index
            confusing_cases = self.data.iloc[incorrect_indices].head(5)

            for _, row in confusing_cases.iterrows():
                actual = "Male-dominant" if row['male'] > row['female'] else "Female-dominant"
                print(f"   {row['cause_name'][:30]} ({row['age_group']}): {actual}")
                print(f"      Male: {row['male']:,.0f}, Female: {row['female']:,.0f}")

        # 4. æ€§åˆ«æ¨¡å¼çš„ä¸šåŠ¡æ´å¯Ÿ
        print("\n" + "=" * 50)
        print("GENDER PATTERN INSIGHTS")
        print("=" * 50)

        # è®¡ç®—ä¸åŒå¹´é¾„æ®µçš„æ€§åˆ«ä¸»å¯¼æ¨¡å¼
        age_dominance = self.data.groupby('age_group').apply(
            lambda x: pd.Series({
                'male_dominant_cases': (x['male'] > x['female']).sum(),
                'female_dominant_cases': (x['male'] <= x['female']).sum(),
                'total_cases': len(x)
            })
        ).reset_index()

        age_dominance['male_dominance_rate'] = age_dominance['male_dominant_cases'] / age_dominance['total_cases']

        print("\nğŸ“Š Gender Dominance by Age Group:")
        for _, row in age_dominance.iterrows():
            dominance = "Male-dominant" if row['male_dominance_rate'] > 0.5 else "Female-dominant"
            print(f"   {row['age_group']:15} {dominance} ({row['male_dominance_rate']:.3f})")

        # æ‰¾å‡ºæ€§åˆ«å·®å¼‚æœ€æ˜¾è‘—çš„æ­»å› ï¼ˆä¿®å¤æ˜¾ç¤ºé—®é¢˜ï¼‰
        print("\nğŸ¯ Most Gender-Specific Causes:")

        # å¤„ç†æ— ç©·å¤§å€¼ï¼Œåˆ›å»ºä¸€ä¸ªæ›´å‹å¥½çš„æ˜¾ç¤º
        extreme_causes = cause_gender_stats.copy()
        extreme_causes['display_ratio'] = extreme_causes.apply(
            lambda row: 'âˆ' if (row['female'] == 0 or row['male'] == 0) else f"{row['m_f_ratio']:.2f}",
            axis=1
        )

        # ç­›é€‰æ€§åˆ«ç‰¹å¼‚æ€§å¼ºçš„ç–¾ç—…ï¼ˆæ¯”ä¾‹>2æˆ–<0.5ï¼‰
        gender_specific = extreme_causes[
            (extreme_causes['m_f_ratio'] > 2.0) | (extreme_causes['m_f_ratio'] < 0.5)
            ].sort_values('m_f_ratio', ascending=False)

        for _, row in gender_specific.head(10).iterrows():
            if row['female'] == 0:
                print(f"   ğŸš¹ {row['cause_name'][:40]}: Male-only disease ({row['male']:,.0f} deaths)")
            elif row['male'] == 0:
                print(f"   ğŸšº {row['cause_name'][:40]}: Female-only disease ({row['female']:,.0f} deaths)")
            elif row['m_f_ratio'] > 2.0:
                print(f"   ğŸš¹ {row['cause_name'][:40]}: {row['display_ratio']}x more male deaths")
            else:
                female_multiple = 1 / row['m_f_ratio']
                print(f"   ğŸšº {row['cause_name'][:40]}: {female_multiple:.2f}x more female deaths")

        # 5. é¢å¤–çš„æ€§åˆ«å·®å¼‚æ´å¯Ÿ
        print("\n" + "=" * 50)
        print("ADDITIONAL GENDER INSIGHTS")
        print("=" * 50)

        # è®¡ç®—æ€§åˆ«å·®å¼‚çš„ç»Ÿè®¡æ˜¾è‘—æ€§
        print("\nğŸ“Š Statistical Significance of Gender Differences:")

        # æŒ‰å¹´é¾„ç»„è¿›è¡Œé…å¯¹tæ£€éªŒ
        from scipy.stats import ttest_rel

        age_groups = self.data['age_group'].unique()
        significant_age_groups = []

        for age_group in age_groups:
            age_data = self.data[self.data['age_group'] == age_group]
            if len(age_data) > 1:
                t_stat, p_value = ttest_rel(age_data['male'], age_data['female'])
                if p_value < 0.05:
                    direction = "Male > Female" if age_data['male'].mean() > age_data['female'].mean() else "Female > Male"
                    significant_age_groups.append({
                        'age_group': age_group,
                        'p_value': p_value,
                        'direction': direction,
                        'mean_diff': age_data['male'].mean() - age_data['female'].mean()
                    })

        if significant_age_groups:
            print("   Age groups with significant gender differences (p < 0.05):")
            for item in sorted(significant_age_groups, key=lambda x: x['p_value']):
                print(f"   {item['age_group']:15} {item['direction']} (p={item['p_value']:.6f}, diff={item['mean_diff']:.1f})")
        else:
            print("   No significant gender differences found by age group")

        self.results["gender_ml"] = {
            'model_results': results,
            'age_gender_stats': age_gender_stats,
            'cause_gender_stats': cause_gender_stats,
            'age_dominance': age_dominance,
            'significant_age_groups': significant_age_groups
        }

        return self.results["gender_ml"]



    def age_pattern_clustering(self):
        """
        ä½¿ç”¨èšç±»åˆ†æè¯†åˆ«å¹´é¾„ç»„æ¨¡å¼
        """
        print("\n" + "=" * 50)
        print("AGE GROUP PATTERN CLUSTERING")
        print("=" * 50)

        # å‡†å¤‡èšç±»ç‰¹å¾
        cluster_features = ['both_sexes', 'male', 'female', 'male_ratio', 'log_deaths']
        X_cluster = self.data[cluster_features].copy()

        # æ ‡å‡†åŒ–
        X_cluster_scaled = self.scaler.fit_transform(X_cluster)

        # ä½¿ç”¨è‚˜éƒ¨æ³•åˆ™ç¡®å®šæœ€ä½³èšç±»æ•°
        inertias = []
        K_range = range(2, 8)

        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42)
            kmeans.fit(X_cluster_scaled)
            inertias.append(kmeans.inertia_)

        # é€‰æ‹©æœ€ä½³Kï¼ˆç®€åŒ–ç‰ˆï¼Œé€‰æ‹©æ‹ç‚¹ï¼‰
        best_k = 3  # å¯ä»¥æ ¹æ®è‚˜éƒ¨æ³•åˆ™åŠ¨æ€é€‰æ‹©

        # æ‰§è¡Œèšç±»
        kmeans = KMeans(n_clusters=best_k, random_state=42)
        cluster_labels = kmeans.fit_predict(X_cluster_scaled)
        self.data['cluster'] = cluster_labels

        # åˆ†æèšç±»ç»“æœ
        print(f"ğŸ“ˆ Clustering Results (K={best_k}):")

        for cluster_id in range(best_k):
            cluster_data = self.data[self.data['cluster'] == cluster_id]
            print(f"\n   Cluster {cluster_id} (n={len(cluster_data)}):")
            print(f"   Mean deaths: {cluster_data['both_sexes'].mean():.1f}")
            print(f"   Male ratio: {cluster_data['male_ratio'].mean():.3f}")
            print(f"   Common age groups: {cluster_data['age_group'].mode().values[:3]}")

        # èšç±»ä¸­å¿ƒè§£é‡Š
        print("\nğŸ“Š Cluster Centers Interpretation:")
        centers = self.scaler.inverse_transform(kmeans.cluster_centers_)
        center_df = pd.DataFrame(centers, columns=cluster_features)
        print(center_df.round(2))

        self.results["age_clustering"] = {
            'model': kmeans,
            'labels': cluster_labels,
            'centers': centers
        }

        return self.results["age_clustering"]

    def regularized_correlation_analysis(self):
        """
        ä½¿ç”¨æ­£åˆ™åŒ–å›å½’åˆ†æå˜é‡å…³ç³»
        """
        print("\n" + "=" * 50)
        print("REGULARIZED CORRELATION ANALYSIS")
        print("=" * 50)

        # å‡†å¤‡å›å½’æ•°æ®
        X = self.data[['age_numeric', 'male', 'female', 'cause_encoded']]
        y = self.data['both_sexes']

        # æ ‡å‡†åŒ–ç‰¹å¾
        X_scaled = self.scaler.fit_transform(X)

        # å¤šç§æ­£åˆ™åŒ–å›å½’æ¨¡å‹
        models = {
            'Lasso': Lasso(alpha=0.1),
            'Ridge': Ridge(alpha=1.0),
            'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5)
        }

        results = {}

        for name, model in models.items():
            # äº¤å‰éªŒè¯è¯„ä¼°
            cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')
            rmse_scores = np.sqrt(-cv_scores)

            # è®­ç»ƒæ¨¡å‹
            model.fit(X_scaled, y)

            # é¢„æµ‹å’Œè¯„ä¼°
            y_pred = model.predict(X_scaled)
            train_rmse = np.sqrt(mean_squared_error(y, y_pred))
            r2 = r2_score(y, y_pred)

            results[name] = {
                'cv_rmse_mean': rmse_scores.mean(),
                'cv_rmse_std': rmse_scores.std(),
                'train_rmse': train_rmse,
                'r2_score': r2,
                'coefficients': model.coef_,
                'model': model
            }

            print(f"ğŸ“ˆ {name}:")
            print(f"   CV RMSE: {rmse_scores.mean():.1f} Â± {rmse_scores.std():.1f}")
            print(f"   Train RMSE: {train_rmse:.1f}")
            print(f"   RÂ² Score: {r2:.3f}")

        # åˆ†ææœ€ä½³æ¨¡å‹çš„ç³»æ•°
        best_model = min(results.items(), key=lambda x: x[1]['cv_rmse_mean'])
        print(f"\nğŸ† Best Model: {best_model[0]} (RMSE: {best_model[1]['cv_rmse_mean']:.1f})")

        print("\nğŸ“Š Feature Coefficients:")
        coef_df = pd.DataFrame({
            'feature': X.columns,
            'coefficient': best_model[1]['coefficients']
        }).sort_values('coefficient', key=abs, ascending=False)

        for _, row in coef_df.iterrows():
            print(f"   {row['feature']}: {row['coefficient']:.3f}")

        self.results["regularized_correlation"] = results
        return results

    def death_prediction_analysis(self):
        """
        ä½¿ç”¨å¤šç§MLå›å½’ç®—æ³•é¢„æµ‹æ­»äº¡æ•°
        """
        print("\n" + "=" * 50)
        print("DEATH PREDICTION ML ANALYSIS")
        print("=" * 50)

        # å‡†å¤‡é¢„æµ‹æ•°æ®
        features = ['age_numeric', 'male', 'female', 'male_ratio', 'cause_encoded']
        X = self.data[features]
        y = self.data['both_sexes']

        # æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)

        # å¤šç§å›å½’å™¨
        regressors = {
            'KNN': KNeighborsRegressor(),
            'SVR': SVR(),
            'Decision Tree': DecisionTreeRegressor(max_depth=10),
            'Random Forest': RandomForestRegressor(n_estimators=100),
            'Ridge': Ridge(alpha=1.0)
        }

        results = {}

        for name, reg in regressors.items():
            # äº¤å‰éªŒè¯
            cv_scores = cross_val_score(reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')
            rmse_scores = np.sqrt(-cv_scores)

            # è®­ç»ƒæµ‹è¯•åˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.3, random_state=42
            )
            reg.fit(X_train, y_train)

            # æµ‹è¯•è¯„ä¼°
            y_pred = reg.predict(X_test)
            test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            test_r2 = r2_score(y_test, y_pred)

            results[name] = {
                'cv_rmse_mean': rmse_scores.mean(),
                'cv_rmse_std': rmse_scores.std(),
                'test_rmse': test_rmse,
                'test_r2': test_r2,
                'model': reg
            }

            print(f"ğŸ“ˆ {name}:")
            print(f"   CV RMSE: {rmse_scores.mean():.1f} Â± {rmse_scores.std():.1f}")
            print(f"   Test RMSE: {test_rmse:.1f}")
            print(f"   Test RÂ²: {test_r2:.3f}")

        # æœ€ä½³æ¨¡å‹è¯¦ç»†åˆ†æ
        best_model = min(results.items(), key=lambda x: x[1]['test_rmse'])
        print(f"\nğŸ† Best Model: {best_model[0]} (RMSE: {best_model[1]['test_rmse']:.1f})")

        # ç‰¹å¾é‡è¦æ€§ï¼ˆå¯¹äºæ ‘æ¨¡å‹ï¼‰
        if best_model[0] in ['Decision Tree', 'Random Forest']:
            model = best_model[1]['model']
            importances = model.feature_importances_
            feature_importance = pd.DataFrame({
                'feature': features,
                'importance': importances
            }).sort_values('importance', ascending=False)

            print("\nğŸ“Š Feature Importance:")
            for _, row in feature_importance.iterrows():
                print(f"   {row['feature']}: {row['importance']:.3f}")

        self.results["death_prediction"] = results
        return results

    def bias_variance_analysis(self):
        """
        åå·®-æ–¹å·®æƒè¡¡åˆ†æï¼ˆå›å½’ä»»åŠ¡ï¼‰
        """
        print("\n" + "=" * 50)
        print("BIAS-VARIANCE TRADEOFF ANALYSIS")
        print("=" * 50)

        # å‡†å¤‡æ•°æ®
        X = self.data[['age_numeric', 'male', 'female', 'cause_encoded']]
        y = self.data['both_sexes']
        X_scaled = self.scaler.fit_transform(X)

        # ä¸åŒå¤æ‚åº¦çš„å›å½’æ¨¡å‹
        models = {
            'High Bias (Linear)': Ridge(alpha=10.0),
            'Balanced (RF-50)': RandomForestRegressor(n_estimators=50, max_depth=5),
            'High Variance (RF-200)': RandomForestRegressor(n_estimators=200, max_depth=None),
            'Medium (KNN-3)': KNeighborsRegressor(n_neighbors=3),
            'Low Variance (KNN-10)': KNeighborsRegressor(n_neighbors=10)
        }

        results = {}

        for name, model in models.items():
            # è®­ç»ƒé›†å’ŒéªŒè¯é›†æ€§èƒ½
            X_train, X_val, y_train, y_val = train_test_split(
                X_scaled, y, test_size=0.3, random_state=42
            )

            model.fit(X_train, y_train)
            train_score = model.score(X_train, y_train)
            val_score = model.score(X_val, y_val)

            # äº¤å‰éªŒè¯
            cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='r2')

            # RMSEè®¡ç®—
            train_pred = model.predict(X_train)
            val_pred = model.predict(X_val)
            train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
            val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))

            results[name] = {
                'train_r2': train_score,
                'val_r2': val_score,
                'train_rmse': train_rmse,
                'val_rmse': val_rmse,
                'cv_r2_mean': cv_scores.mean(),
                'cv_r2_std': cv_scores.std(),
                'overfitting_gap': train_score - val_score  # è¿‡æ‹ŸåˆæŒ‡æ ‡
            }

            print(f"ğŸ“ˆ {name}:")
            print(f"   Train RÂ²: {train_score:.3f}, Val RÂ²: {val_score:.3f}")
            print(f"   Train RMSE: {train_rmse:.1f}, Val RMSE: {val_rmse:.1f}")
            print(f"   Overfitting Gap: {train_score - val_score:.3f}")
            print(f"   CV RÂ²: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")

        # æ‰¾å‡ºæœ€ä½³åå·®-æ–¹å·®å¹³è¡¡
        best_balanced = min(results.items(), key=lambda x: abs(x[1]['overfitting_gap']))
        print(f"\nğŸ† Best Bias-Variance Balance: {best_balanced[0]}")
        print(f"   Overfitting Gap: {abs(best_balanced[1]['overfitting_gap']):.3f}")
        print(f"   Validation RÂ²: {best_balanced[1]['val_r2']:.3f}")

        # åå·®-æ–¹å·®å¯è§†åŒ–å»ºè®®
        print("\nğŸ“Š Bias-Variance Interpretation:")
        for name, result in results.items():
            if result['overfitting_gap'] > 0.2:
                print(f"   {name}: High variance (overfitting)")
            elif result['val_r2'] < 0.3:
                print(f"   {name}: High bias (underfitting)")
            else:
                print(f"   {name}: Good balance")

        self.results["bias_variance"] = results
        return results

    def run_all_ml_tests(self):
        """
        è¿è¡Œæ‰€æœ‰æœºå™¨å­¦ä¹ åˆ†æ
        """
        print("\n" + "=" * 60)
        print("  RUNNING ALL MACHINE LEARNING ANALYSES")
        print("=" * 60)

        # 1. æè¿°æ€§ç»Ÿè®¡
        self.descriptive_statistics()

        # 2. æ€§åˆ«å·®å¼‚MLåˆ†æ
        self.gender_classification_analysis()

        # 3. å¹´é¾„æ¨¡å¼èšç±»
        self.age_pattern_clustering()

        # 4. æ­£åˆ™åŒ–ç›¸å…³æ€§åˆ†æ
        self.regularized_correlation_analysis()

        # 5. æ­»äº¡æ•°é¢„æµ‹åˆ†æ
        self.death_prediction_analysis()

        # 6. åå·®-æ–¹å·®åˆ†æ
        self.bias_variance_analysis()

        # åˆ›å»ºç»“æœæ‘˜è¦
        print("\n" + "=" * 60)
        print("  MACHINE LEARNING ANALYSIS SUMMARY")
        print("=" * 60)

        summary_data = []

        # æ€§åˆ«åˆ†ææ‘˜è¦ - ä¿®å¤è®¿é—®è·¯å¾„
        if 'gender_ml' in self.results and 'model_results' in self.results['gender_ml']:
            model_results = self.results['gender_ml']['model_results']
            if model_results:
                best_gender = max(model_results.items(),
                                  key=lambda x: x[1]['test_accuracy'])
                summary_data.append({
                    'Analysis': 'Gender Classification',
                    'Best Model': best_gender[0],
                    'Performance': f"{best_gender[1]['test_accuracy']:.3f}"
                })

        # æ­£åˆ™åŒ–å›å½’æ‘˜è¦
        if 'regularized_correlation' in self.results:
            best_reg = min(self.results['regularized_correlation'].items(),
                           key=lambda x: x[1]['cv_rmse_mean'])
            summary_data.append({
                'Analysis': 'Regularized Regression',
                'Best Model': best_reg[0],
                'Performance': f"RMSE: {best_reg[1]['cv_rmse_mean']:.1f}"
            })

        # æ­»äº¡é¢„æµ‹æ‘˜è¦
        if 'death_prediction' in self.results:
            best_pred = min(self.results['death_prediction'].items(),
                            key=lambda x: x[1]['test_rmse'])
            summary_data.append({
                'Analysis': 'Death Prediction',
                'Best Model': best_pred[0],
                'Performance': f"RMSE: {best_pred[1]['test_rmse']:.1f}"
            })

        summary_df = pd.DataFrame(summary_data)
        if not summary_df.empty:
            print("\nğŸ“Š ML Analysis Summary:")
            print(summary_df.to_string(index=False))

        # é¢å¤–çš„æ€§åˆ«åˆ†ææ‘˜è¦
        if 'gender_ml' in self.results:
            print("\n" + "=" * 60)
            print("  GENDER ANALYSIS HIGHLIGHTS")
            print("=" * 60)

            gender_results = self.results['gender_ml']

            # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹
            if 'model_results' in gender_results:
                best_model = max(gender_results['model_results'].items(),
                                 key=lambda x: x[1]['test_accuracy'])
                print(f"\nğŸ† Best Gender Classification Model: {best_model[0]}")
                print(f"   Accuracy: {best_model[1]['test_accuracy']:.3f}")
                print(f"   CV Score: {best_model[1]['cv_mean']:.3f} Â± {best_model[1]['cv_std']:.3f}")

            # æ˜¾ç¤ºæ€§åˆ«å·®å¼‚ç»Ÿè®¡
            if 'age_dominance' in gender_results:
                print(f"\nğŸ“Š Age Group Gender Dominance:")
                for _, row in gender_results['age_dominance'].iterrows():
                    dominance = "Male" if row['male_dominance_rate'] > 0.5 else "Female"
                    print(f"   {row['age_group']:15}: {dominance}-dominant ({row['male_dominance_rate']:.3f})")

            # æ˜¾ç¤ºæ˜¾è‘—çš„å¹´é¾„ç»„
            if 'significant_age_groups' in gender_results and gender_results['significant_age_groups']:
                print(f"\nğŸ”¬ Significant Gender Differences by Age:")
                for item in sorted(gender_results['significant_age_groups'], key=lambda x: x['p_value'])[:3]:
                    print(f"   {item['age_group']}: {item['direction']} (p={item['p_value']:.6f})")

        return self.results



# ä¸»ç¨‹åº
if __name__ == "__main__":
    print("=" * 60)
    print("  WHO Mortality Machine Learning Analysis")
    print("=" * 60)

    try:
        # åŠ è½½æ•°æ®
        data_path = "data/processed/who_mortality_clean.csv"

        if not pd.io.common.file_exists(data_path):
            print(f"âŒ Error: Processed data not found at {data_path}")
            print("   Please run data_processing.py first.")
            exit(1)

        print(f"ğŸ“‚ Loading data from {data_path}...")
        data = pd.read_csv(data_path)
        print(f"âœ… Loaded {len(data)} records")

        # åˆå§‹åŒ–MLåˆ†æå™¨
        analyzer = MLStatistics(data)

        # è¿è¡Œæ‰€æœ‰åˆ†æ
        results = analyzer.run_all_ml_tests()

        print("\n" + "=" * 60)
        print("  MACHINE LEARNING ANALYSIS COMPLETE")
        print("=" * 60)
        print("\nâœ… All ML analyses completed successfully!")
        print("   Results have been stored in the analyzer.results dictionary")

    except Exception as e:
        print(f"\nâŒ Error during analysis: {e}")
        import traceback
        traceback.print_exc()
